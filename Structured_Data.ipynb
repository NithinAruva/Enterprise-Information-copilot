{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5227b4dc-2650-4438-9ad9-5b1576a4bf92",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: databricks-vectorsearch in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.11/site-packages (0.40)\nRequirement already satisfied: mlflow-skinny<3,>=2.11.3 in /databricks/python3/lib/python3.11/site-packages (from databricks-vectorsearch) (2.13.1)\nRequirement already satisfied: protobuf<5,>=3.12.0 in /databricks/python3/lib/python3.11/site-packages (from databricks-vectorsearch) (4.24.1)\nRequirement already satisfied: requests>=2 in /databricks/python3/lib/python3.11/site-packages (from databricks-vectorsearch) (2.31.0)\nRequirement already satisfied: deprecation>=2 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.11/site-packages (from databricks-vectorsearch) (2.1.0)\nRequirement already satisfied: packaging in /databricks/python3/lib/python3.11/site-packages (from deprecation>=2->databricks-vectorsearch) (23.2)\nRequirement already satisfied: cachetools<6,>=5.0.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny<3,>=2.11.3->databricks-vectorsearch) (5.4.0)\nRequirement already satisfied: click<9,>=7.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny<3,>=2.11.3->databricks-vectorsearch) (8.0.4)\nRequirement already satisfied: cloudpickle<4 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny<3,>=2.11.3->databricks-vectorsearch) (2.2.1)\nRequirement already satisfied: entrypoints<1 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny<3,>=2.11.3->databricks-vectorsearch) (0.4)\nRequirement already satisfied: gitpython<4,>=3.1.9 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny<3,>=2.11.3->databricks-vectorsearch) (3.1.27)\nRequirement already satisfied: importlib-metadata!=4.7.0,<8,>=3.7.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny<3,>=2.11.3->databricks-vectorsearch) (6.0.0)\nRequirement already satisfied: opentelemetry-api<3,>=1.0.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny<3,>=2.11.3->databricks-vectorsearch) (1.25.0)\nRequirement already satisfied: opentelemetry-sdk<3,>=1.0.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny<3,>=2.11.3->databricks-vectorsearch) (1.25.0)\nRequirement already satisfied: pytz<2025 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny<3,>=2.11.3->databricks-vectorsearch) (2022.7)\nRequirement already satisfied: pyyaml<7,>=5.1 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny<3,>=2.11.3->databricks-vectorsearch) (6.0)\nRequirement already satisfied: sqlparse<1,>=0.4.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny<3,>=2.11.3->databricks-vectorsearch) (0.4.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.11/site-packages (from requests>=2->databricks-vectorsearch) (2.0.4)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.11/site-packages (from requests>=2->databricks-vectorsearch) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /databricks/python3/lib/python3.11/site-packages (from requests>=2->databricks-vectorsearch) (1.26.16)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.11/site-packages (from requests>=2->databricks-vectorsearch) (2023.7.22)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /databricks/python3/lib/python3.11/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny<3,>=2.11.3->databricks-vectorsearch) (4.0.11)\nRequirement already satisfied: zipp>=0.5 in /databricks/python3/lib/python3.11/site-packages (from importlib-metadata!=4.7.0,<8,>=3.7.0->mlflow-skinny<3,>=2.11.3->databricks-vectorsearch) (3.11.0)\nRequirement already satisfied: deprecated>=1.2.6 in /databricks/python3/lib/python3.11/site-packages (from opentelemetry-api<3,>=1.0.0->mlflow-skinny<3,>=2.11.3->databricks-vectorsearch) (1.2.14)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.46b0 in /databricks/python3/lib/python3.11/site-packages (from opentelemetry-sdk<3,>=1.0.0->mlflow-skinny<3,>=2.11.3->databricks-vectorsearch) (0.46b0)\nRequirement already satisfied: typing-extensions>=3.7.4 in /databricks/python3/lib/python3.11/site-packages (from opentelemetry-sdk<3,>=1.0.0->mlflow-skinny<3,>=2.11.3->databricks-vectorsearch) (4.10.0)\nRequirement already satisfied: wrapt<2,>=1.10 in /databricks/python3/lib/python3.11/site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.0.0->mlflow-skinny<3,>=2.11.3->databricks-vectorsearch) (1.14.1)\nRequirement already satisfied: smmap<6,>=3.0.1 in /databricks/python3/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny<3,>=2.11.3->databricks-vectorsearch) (5.0.0)\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "#Instalations\n",
    "%pip install databricks-vectorsearch\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9cc45774-aaec-4814-814e-abdd52f83ce8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mPy4JJavaError\u001B[0m                             Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-3894095008779751>, line 2\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Input Query\u001B[39;00m\n",
       "\u001B[0;32m----> 2\u001B[0m question \u001B[38;5;241m=\u001B[39m dbutils\u001B[38;5;241m.\u001B[39mwidgets\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mquery\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
       "\n",
       "File \u001B[0;32m/databricks/python_shell/dbruntime/WidgetHandlerImpl.py:77\u001B[0m, in \u001B[0;36mWidgetsHandlerImpl.get\u001B[0;34m(self, name)\u001B[0m\n",
       "\u001B[1;32m     37\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget\u001B[39m(\u001B[38;5;28mself\u001B[39m, name):\n",
       "\u001B[1;32m     38\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\" Returns the current value of a widget with the given name.\u001B[39;00m\n",
       "\u001B[1;32m     39\u001B[0m \n",
       "\u001B[1;32m     40\u001B[0m \u001B[38;5;124;03m    :param name: Name of the argument to be accessed\u001B[39;00m\n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m     75\u001B[0m \u001B[38;5;124;03m        ```\u001B[39;00m\n",
       "\u001B[1;32m     76\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n",
       "\u001B[0;32m---> 77\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_notebookArguments\u001B[38;5;241m.\u001B[39mgetArgument(name, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_entry_point\u001B[38;5;241m.\u001B[39mgetCurrentBindings())\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1355\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1349\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1350\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1351\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1352\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n",
       "\u001B[1;32m   1354\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n",
       "\u001B[0;32m-> 1355\u001B[0m return_value \u001B[38;5;241m=\u001B[39m get_return_value(\n",
       "\u001B[1;32m   1356\u001B[0m     answer, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_id, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname)\n",
       "\u001B[1;32m   1358\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n",
       "\u001B[1;32m   1359\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions/captured.py:255\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n",
       "\u001B[1;32m    252\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpy4j\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mprotocol\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Py4JJavaError\n",
       "\u001B[1;32m    254\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m--> 255\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m f(\u001B[38;5;241m*\u001B[39ma, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw)\n",
       "\u001B[1;32m    256\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m Py4JJavaError \u001B[38;5;28;01mas\u001B[39;00m e:\n",
       "\u001B[1;32m    257\u001B[0m     converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py:326\u001B[0m, in \u001B[0;36mget_return_value\u001B[0;34m(answer, gateway_client, target_id, name)\u001B[0m\n",
       "\u001B[1;32m    324\u001B[0m value \u001B[38;5;241m=\u001B[39m OUTPUT_CONVERTER[\u001B[38;5;28mtype\u001B[39m](answer[\u001B[38;5;241m2\u001B[39m:], gateway_client)\n",
       "\u001B[1;32m    325\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m answer[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m==\u001B[39m REFERENCE_TYPE:\n",
       "\u001B[0;32m--> 326\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Py4JJavaError(\n",
       "\u001B[1;32m    327\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAn error occurred while calling \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39m\n",
       "\u001B[1;32m    328\u001B[0m         \u001B[38;5;28mformat\u001B[39m(target_id, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, name), value)\n",
       "\u001B[1;32m    329\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m    330\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Py4JError(\n",
       "\u001B[1;32m    331\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAn error occurred while calling \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m. Trace:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{3}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39m\n",
       "\u001B[1;32m    332\u001B[0m         \u001B[38;5;28mformat\u001B[39m(target_id, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, name, value))\n",
       "\n",
       "\u001B[0;31mPy4JJavaError\u001B[0m: An error occurred while calling o391.getArgument.\n",
       ": com.databricks.dbutils_v1.InputWidgetNotDefined: No input widget named query is defined\n",
       "\tat com.databricks.backend.daemon.driver.NotebookArguments.checkExists(NotebookArguments.scala:72)\n",
       "\tat com.databricks.backend.daemon.driver.NotebookArguments.getArgument(NotebookArguments.scala:264)\n",
       "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
       "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
       "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
       "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
       "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
       "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)\n",
       "\tat py4j.Gateway.invoke(Gateway.java:306)\n",
       "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
       "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
       "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)\n",
       "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:119)\n",
       "\tat java.lang.Thread.run(Thread.java:750)\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "Py4JJavaError",
        "evalue": "An error occurred while calling o391.getArgument.\n: com.databricks.dbutils_v1.InputWidgetNotDefined: No input widget named query is defined\n\tat com.databricks.backend.daemon.driver.NotebookArguments.checkExists(NotebookArguments.scala:72)\n\tat com.databricks.backend.daemon.driver.NotebookArguments.getArgument(NotebookArguments.scala:264)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)\n\tat py4j.Gateway.invoke(Gateway.java:306)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:119)\n\tat java.lang.Thread.run(Thread.java:750)\n"
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>Py4JJavaError</span>: An error occurred while calling o391.getArgument.\n: com.databricks.dbutils_v1.InputWidgetNotDefined: No input widget named query is defined\n\tat com.databricks.backend.daemon.driver.NotebookArguments.checkExists(NotebookArguments.scala:72)\n\tat com.databricks.backend.daemon.driver.NotebookArguments.getArgument(NotebookArguments.scala:264)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)\n\tat py4j.Gateway.invoke(Gateway.java:306)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:119)\n\tat java.lang.Thread.run(Thread.java:750)\n"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mPy4JJavaError\u001B[0m                             Traceback (most recent call last)",
        "File \u001B[0;32m<command-3894095008779751>, line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Input Query\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m question \u001B[38;5;241m=\u001B[39m dbutils\u001B[38;5;241m.\u001B[39mwidgets\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mquery\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
        "File \u001B[0;32m/databricks/python_shell/dbruntime/WidgetHandlerImpl.py:77\u001B[0m, in \u001B[0;36mWidgetsHandlerImpl.get\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m     37\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget\u001B[39m(\u001B[38;5;28mself\u001B[39m, name):\n\u001B[1;32m     38\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\" Returns the current value of a widget with the given name.\u001B[39;00m\n\u001B[1;32m     39\u001B[0m \n\u001B[1;32m     40\u001B[0m \u001B[38;5;124;03m    :param name: Name of the argument to be accessed\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     75\u001B[0m \u001B[38;5;124;03m        ```\u001B[39;00m\n\u001B[1;32m     76\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 77\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_notebookArguments\u001B[38;5;241m.\u001B[39mgetArgument(name, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_entry_point\u001B[38;5;241m.\u001B[39mgetCurrentBindings())\n",
        "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1355\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1349\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1350\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1351\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1352\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1354\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1355\u001B[0m return_value \u001B[38;5;241m=\u001B[39m get_return_value(\n\u001B[1;32m   1356\u001B[0m     answer, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_id, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname)\n\u001B[1;32m   1358\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1359\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
        "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions/captured.py:255\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    252\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpy4j\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mprotocol\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Py4JJavaError\n\u001B[1;32m    254\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 255\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m f(\u001B[38;5;241m*\u001B[39ma, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw)\n\u001B[1;32m    256\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m Py4JJavaError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    257\u001B[0m     converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n",
        "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py:326\u001B[0m, in \u001B[0;36mget_return_value\u001B[0;34m(answer, gateway_client, target_id, name)\u001B[0m\n\u001B[1;32m    324\u001B[0m value \u001B[38;5;241m=\u001B[39m OUTPUT_CONVERTER[\u001B[38;5;28mtype\u001B[39m](answer[\u001B[38;5;241m2\u001B[39m:], gateway_client)\n\u001B[1;32m    325\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m answer[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m==\u001B[39m REFERENCE_TYPE:\n\u001B[0;32m--> 326\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Py4JJavaError(\n\u001B[1;32m    327\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAn error occurred while calling \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39m\n\u001B[1;32m    328\u001B[0m         \u001B[38;5;28mformat\u001B[39m(target_id, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, name), value)\n\u001B[1;32m    329\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    330\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Py4JError(\n\u001B[1;32m    331\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAn error occurred while calling \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m. Trace:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{3}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39m\n\u001B[1;32m    332\u001B[0m         \u001B[38;5;28mformat\u001B[39m(target_id, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, name, value))\n",
        "\u001B[0;31mPy4JJavaError\u001B[0m: An error occurred while calling o391.getArgument.\n: com.databricks.dbutils_v1.InputWidgetNotDefined: No input widget named query is defined\n\tat com.databricks.backend.daemon.driver.NotebookArguments.checkExists(NotebookArguments.scala:72)\n\tat com.databricks.backend.daemon.driver.NotebookArguments.getArgument(NotebookArguments.scala:264)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)\n\tat py4j.Gateway.invoke(Gateway.java:306)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:119)\n\tat java.lang.Thread.run(Thread.java:750)\n"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Input Query  \n",
    "question = dbutils.widgets.get('query')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7dd1edf8-00ab-485b-8e1f-fb55578741f1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NOTICE] Using a notebook authentication token. Recommended for development only. For improved performance, please use Service Principal based authentication. To disable this message, pass disable_notice=True to VectorSearchClient().\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-3894095008779740>, line 14\u001B[0m\n",
       "\u001B[1;32m      6\u001B[0m sp_client_secret \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39menviron\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSP_CLIENT_SECRET\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[1;32m      7\u001B[0m vsc \u001B[38;5;241m=\u001B[39m VectorSearchClient(\n",
       "\u001B[1;32m      8\u001B[0m     workspace_url\u001B[38;5;241m=\u001B[39mworkspace_url,\n",
       "\u001B[1;32m      9\u001B[0m     service_principal_client_id\u001B[38;5;241m=\u001B[39msp_client_id,\n",
       "\u001B[1;32m     10\u001B[0m     service_principal_client_secret\u001B[38;5;241m=\u001B[39msp_client_secret\n",
       "\u001B[1;32m     11\u001B[0m )\n",
       "\u001B[1;32m     13\u001B[0m results \u001B[38;5;241m=\u001B[39m vsc\u001B[38;5;241m.\u001B[39mget_index(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mspectra_classification1\u001B[39m\u001B[38;5;124m\"\u001B[39m,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmain.default.spectraclassification1_index\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39msimilarity_search(\n",
       "\u001B[0;32m---> 14\u001B[0m   query_text\u001B[38;5;241m=\u001B[39mquestion,\n",
       "\u001B[1;32m     15\u001B[0m   columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mChunks\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n",
       "\u001B[1;32m     16\u001B[0m   num_results\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m)\n",
       "\u001B[1;32m     17\u001B[0m rest \u001B[38;5;241m=\u001B[39m results\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mresult\u001B[39m\u001B[38;5;124m'\u001B[39m, {})\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata_array\u001B[39m\u001B[38;5;124m'\u001B[39m, [])\n",
       "\u001B[1;32m     18\u001B[0m rest\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'question' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "NameError",
        "evalue": "name 'question' is not defined"
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'question' is not defined"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
        "File \u001B[0;32m<command-3894095008779740>, line 14\u001B[0m\n\u001B[1;32m      6\u001B[0m sp_client_secret \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39menviron\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSP_CLIENT_SECRET\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      7\u001B[0m vsc \u001B[38;5;241m=\u001B[39m VectorSearchClient(\n\u001B[1;32m      8\u001B[0m     workspace_url\u001B[38;5;241m=\u001B[39mworkspace_url,\n\u001B[1;32m      9\u001B[0m     service_principal_client_id\u001B[38;5;241m=\u001B[39msp_client_id,\n\u001B[1;32m     10\u001B[0m     service_principal_client_secret\u001B[38;5;241m=\u001B[39msp_client_secret\n\u001B[1;32m     11\u001B[0m )\n\u001B[1;32m     13\u001B[0m results \u001B[38;5;241m=\u001B[39m vsc\u001B[38;5;241m.\u001B[39mget_index(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mspectra_classification1\u001B[39m\u001B[38;5;124m\"\u001B[39m,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmain.default.spectraclassification1_index\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39msimilarity_search(\n\u001B[0;32m---> 14\u001B[0m   query_text\u001B[38;5;241m=\u001B[39mquestion,\n\u001B[1;32m     15\u001B[0m   columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mChunks\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m     16\u001B[0m   num_results\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m)\n\u001B[1;32m     17\u001B[0m rest \u001B[38;5;241m=\u001B[39m results\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mresult\u001B[39m\u001B[38;5;124m'\u001B[39m, {})\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata_array\u001B[39m\u001B[38;5;124m'\u001B[39m, [])\n\u001B[1;32m     18\u001B[0m rest\n",
        "\u001B[0;31mNameError\u001B[0m: name 'question' is not defined"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Querying the Vector Search Index\n",
    "import os\n",
    "from databricks.vector_search.client import VectorSearchClient\n",
    "workspace_url = os.environ.get(\"WORKSPACE_URL\")\n",
    "sp_client_id = os.environ.get(\"SP_CLIENT_ID\")\n",
    "sp_client_secret = os.environ.get(\"SP_CLIENT_SECRET\")\n",
    "vsc = VectorSearchClient(\n",
    "    workspace_url=workspace_url,\n",
    "    service_principal_client_id=sp_client_id,\n",
    "    service_principal_client_secret=sp_client_secret\n",
    ")\n",
    "\n",
    "results = vsc.get_index(\"spectra_classification1\",\"main.default.spectraclassification1_index\").similarity_search(\n",
    "  query_text=question,\n",
    "  columns=[\"Chunks\"],\n",
    "  num_results=5)\n",
    "rest = results.get('result', {}).get('data_array', [])\n",
    "rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc1f27c0-fdf1-4b04-8460-80632491500b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# For sql query generation\n",
    "chain_config = {\n",
    "    \"llm_model_serving_endpoint_name\": \"databricks-meta-llama-3-1-405b-instruct\",\n",
    "    \"vector_search_endpoint_name\": \"spectra_classification1\",\n",
    "    \"vector_search_index\": \"main.default.spectraclassification1_index\",\n",
    "    \"llm_prompt_template\": \"\"\"You are a SQL expert. Based on the classification information provided and the input query, generate a syntactically correct SQL query to run and return ONLY the generated query and nothing else.\\n\\n\\\n",
    "        The classification information contains details about the relevant subtopics, categories, taxonomy, attributes, entities, and relationships between tables. You must use this information to guide the construction of the SQL query.\\n\\n\\\n",
    "        Classification Chunks: {context}\\n\\n\\\n",
    "        Given this information, generate a SQL query that adheres to the following rules:\\n\\n\\\n",
    "        - **Identify the correct table for each attribute or metric**: Ensure that the SQL query correctly identifies the table from which to retrieve each attribute (e.g., budgets should be retrieved from the **Project** table, not the **Department** table).\\n\\\n",
    "        - **Use the correct aggregation functions**: If the query involves summing, averaging, or counting, make sure the correct aggregation function is applied on the appropriate column (e.g., `SUM(Budget)` when summing project budgets).\\n\\\n",
    "        - **Perform accurate JOIN operations**: Ensure that JOINs are used where necessary based on the relationships between tables (e.g., `Project` and `Department` using `Department_ID`). The JOIN should reflect the relationships outlined in the classification information. Consider all types of JOINS\\n\\\n",
    "        - **Use filtering conditions properly**: When the query asks for specific filtering criteria (e.g., department name, project status, date ranges), make sure to use appropriate filtering conditions like `WHERE`, `AND`, or `OR`.\\n\\\n",
    "        - **Handle date and time-related queries**: When dealing with date or timestamp columns, use the correct functions (e.g., `EXTRACT`, `DATE_PART`, `YEAR`) to filter or aggregate date-related data correctly.\\n\\\n",
    "        - **Group results where necessary**: If the query requires grouping data (e.g., summing by department, counting by project), ensure that `GROUP BY` is used correctly along with aggregate functions.\\n\\\n",
    "        - **Limit rows when necessary**: Ensure that the number of returned rows is restricted if needed, by using `LIMIT` or ensuring only necessary rows are retrieved.\\n\\\n",
    "        - **Check for aliasing where appropriate**: Use aliases to improve query readability, especially when working with multiple tables or complex joins.\\n\\\n",
    "        -**Read the labels correctly**: Make sure the labels are correct and match the classification information and there are some labels which are similar with slight differences like a underscore. Treat them as different columns.(e.g., department_id from T2 is different from deparatment from T1).\\n\\\n",
    "        - Do not include any new-line characters or unnecessary symbols.\\n\\\n",
    "        - Return only the generated SQL query without any additional explanations.\"\"\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "71f22d3f-b5bd-40f4-916b-6aa33d5b8855",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# User input to SQL query conversion\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.chat_models import ChatDatabricks\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [  \n",
    "        (\"system\", chain_config.get(\"llm_prompt_template\")),  \n",
    "        (\"user\", \"{question}\")  # User's input query\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Model for answering using Databricks endpoint\n",
    "model = ChatDatabricks(\n",
    "    endpoint=chain_config.get(\"llm_model_serving_endpoint_name\"),\n",
    "    extra_params={\"temperature\": 0.01, \"max_tokens\": 500}\n",
    ")\n",
    "\n",
    "# Generate the final SQL query based on the user's question and context\n",
    "answer = prompt | model\n",
    "response = answer.invoke({'question': question, 'context': rest})\n",
    "\n",
    "# Extract the SQL query from the response\n",
    "sql = response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6170bea8-4e13-46b1-829c-50fa3d6b5c77",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "USE spectra_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0fd77f4d-9dac-4818-b8ce-e6bebe061025",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Executing the query using Spark SQL\n",
    "output_string = \"\"\n",
    "result_df = spark.sql(sql)\n",
    "result = result_df.collect()\n",
    "\n",
    "if len(result) == 1 and len(result[0]) == 1:\n",
    "    # Single row, single column result- (e.g., COUNT, SUM)\n",
    "    query_result = result[0][0]\n",
    "    output_string = str(query_result)\n",
    "else: \n",
    "    for row in result:\n",
    "    # Convert each row to a string format by iterating over all columns in the row\n",
    "        row_string = ', '.join([str(col) for col in row])\n",
    "        output_string += row_string + \"\\n\"\n",
    "\n",
    "output_string = output_string.strip()\n",
    "print(output_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c3aa5eaa-96a4-4cd9-b09a-9111707e8864",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.notebook.exit(output_string)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Prompt_Structured",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
